I"`1<h2 id="what-are-the-kubernetes-worker-nodes">What are the Kubernetes Worker Nodes?</h2>

<p>Kubernetes worker nodes are responsible for the actual work of running container applications managed by Kubernetes.</p>

<p>“The Kubernetes node has the services necessary to run application containers and be managed from the master systems.”</p>

<h3 id="components">Components</h3>

<ul>
  <li>
    <p><code class="highlighter-rouge">kubelet</code>: controls each worker node, providing the APIs that are used by the control plane to manage nodes and pods, and interacts with the container runtime to manage containers.</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">kube-proxy</code>: Manages iptables rules on the node to provide virtual network access to pods.</p>
  </li>
  <li>
    <p>Container runtime: Downloads images and runs containers, actually not part of Kubernetes and you have multiple options, the most popular is Docker.
In this tutorial we will use containerd</p>
  </li>
</ul>

<p>We need to install these components on each worker node.</p>

<h4 id="resources">Resources</h4>

<ul>
  <li>
    <p><a href="https://kubernetes.io/docs/concepts/architecture/">Kubernetes Architecture</a></p>
  </li>
  <li>
    <p><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/architecture.md#the-kubernetes-node">Kubernetes Node Architecture</a></p>
  </li>
</ul>

<h2 id="worker-node-architecture-overview">Worker Node Architecture Overview</h2>

<h2 id="installing-worker-node-binaries">Installing Worker Node Binaries</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install required packages</span>
<span class="nb">sudo </span>apt-get <span class="nt">-y</span> <span class="nb">install </span>socat conntrack ipset

<span class="c"># Download the binaries that we need</span>
wget <span class="nt">-q</span> <span class="nt">--show-progress</span> <span class="nt">--https-only</span> <span class="nt">--timestamping</span> <span class="se">\</span>
  https://github.com/kubernetes-incubator/cri-tools/releases/download/v1.0.0-beta.0/crictl-v1.0.0-beta.0-linux-amd64.tar.gz <span class="se">\</span>
  https://storage.googleapis.com/kubernetes-the-hard-way/runsc <span class="se">\</span>
  https://github.com/opencontainers/runc/releases/download/v1.0.0-rc5/runc.amd64 <span class="se">\</span>
  https://github.com/containernetworking/plugins/releases/download/v0.6.0/cni-plugins-amd64-v0.6.0.tgz <span class="se">\</span>
  https://github.com/containerd/containerd/releases/download/v1.1.0/containerd-1.1.0.linux-amd64.tar.gz <span class="se">\</span>
  https://storage.googleapis.com/kubernetes-release/release/v1.10.2/bin/linux/amd64/kubectl <span class="se">\</span>
  https://storage.googleapis.com/kubernetes-release/release/v1.10.2/bin/linux/amd64/kube-proxy <span class="se">\</span>
  https://storage.googleapis.com/kubernetes-release/release/v1.10.2/bin/linux/amd64/kubelet

<span class="c"># Create some directories</span>
<span class="nb">sudo mkdir</span> <span class="nt">-p</span> <span class="se">\</span>
  /etc/cni/net.d <span class="se">\</span>
  /opt/cni/bin <span class="se">\</span>
  /var/lib/kubelet <span class="se">\</span>
  /var/lib/kube-proxy <span class="se">\</span>
  /var/lib/kubernetes <span class="se">\</span>
  /var/run/kubernetes

<span class="nb">chmod</span> +x kubectl kube-proxy kubelet runc.amd64 runsc

<span class="nb">sudo mv </span>runc.amd64 runc

<span class="nb">sudo mv </span>kubectl kube-proxy kubelet runc runsc /usr/local/bin/

<span class="c"># Extract the archive files</span>
<span class="nb">sudo tar</span> <span class="nt">-xvf</span> crictl-v1.0.0-beta.0-linux-amd64.tar.gz <span class="nt">-C</span> /usr/local/bin/

<span class="nb">sudo tar</span> <span class="nt">-xvf</span> cni-plugins-amd64-v0.6.0.tgz <span class="nt">-C</span> /opt/cni/bin/

<span class="nb">sudo tar</span> <span class="nt">-xvf</span> containerd-1.1.0.linux-amd64.tar.gz <span class="nt">-C</span> /
</code></pre></div></div>

<h2 id="configuring-containerd">Configuring Containerd</h2>

<p>Containerd is the container runtime we chose to run containers that Kubernetes will manage.
Let’s configure the <code class="highlighter-rouge">systemd</code> service for containerd on both of our workers:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo mkdir</span> <span class="nt">-p</span> /etc/containerd/
</code></pre></div></div>

<p>Then, create the containerd config.toml:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | sudo tee /etc/containerd/config.toml
[plugins]
  [plugins.cri.containerd]
    snapshotter = "overlayfs"
    [plugins.cri.containerd.default_runtime]
      runtime_type = "io.containerd.runtime.v1.linux"
      runtime_engine = "/usr/local/bin/runc"
      runtime_root = ""
    [plugins.cri.containerd.untrusted_workload_runtime]
      runtime_type = "io.containerd.runtime.v1.linux"
      runtime_engine = "/usr/local/bin/runsc"
      runtime_root = "/run/containerd/runsc"
</span><span class="no">EOF
</span></code></pre></div></div>

<p>And lastly, the containerd unit file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | sudo tee /etc/systemd/system/containerd.service
[Unit]
Description=containerd container runtime
Documentation=https://containerd.io
After=network.target

[Service]
ExecStartPre=/sbin/modprobe overlay
ExecStart=/bin/containerd
Restart=always
RestartSec=5
Delegate=yes
KillMode=process
OOMScoreAdjust=-999
LimitNOFILE=1048576
LimitNPROC=infinity
LimitCORE=infinity

[Install]
WantedBy=multi-user.target
</span><span class="no">EOF
</span></code></pre></div></div>

<p>We won’t start the service now, but wait until we finish configuring the 3 services</p>

<h2 id="configuring-kubelet">Configuring Kubelet</h2>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HOSTNAME=icaro4c.mylabserver.com

sudo mv ${HOSTNAME}-key.pem ${HOSTNAME}.pem /var/lib/kubelet/
sudo mv ${HOSTNAME}.kubeconfig /var/lib/kubelet/kubeconfig
sudo mv ca.pem /var/lib/kubernetes/
</code></pre></div></div>

<p>Create the kubelet config file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | sudo tee /var/lib/kubelet/kubelet-config.yaml
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
  x509:
    clientCAFile: "/var/lib/kubernetes/ca.pem"
authorization:
  mode: Webhook
clusterDomain: "cluster.local"
clusterDNS: 
  - "10.32.0.10"
runtimeRequestTimeout: "15m"
tlsCertFile: "/var/lib/kubelet/</span><span class="k">${</span><span class="nv">HOSTNAME</span><span class="k">}</span><span class="sh">.pem"
tlsPrivateKeyFile: "/var/lib/kubelet/</span><span class="k">${</span><span class="nv">HOSTNAME</span><span class="k">}</span><span class="sh">-key.pem"
</span><span class="no">EOF
</span></code></pre></div></div>

<p>And lastly, create the kubelet unit file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | sudo tee /etc/systemd/system/kubelet.service
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=containerd.service
Requires=containerd.service

[Service]
ExecStart=/usr/local/bin/kubelet </span><span class="se">\\</span><span class="sh">
  --config=/var/lib/kubelet/kubelet-config.yaml </span><span class="se">\\</span><span class="sh">
  --container-runtime=remote </span><span class="se">\\</span><span class="sh">
  --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock </span><span class="se">\\</span><span class="sh">
  --image-pull-progress-deadline=2m </span><span class="se">\\</span><span class="sh">
  --kubeconfig=/var/lib/kubelet/kubeconfig </span><span class="se">\\</span><span class="sh">
  --network-plugin=cni </span><span class="se">\\</span><span class="sh">
  --register-node=true </span><span class="se">\\</span><span class="sh">
  --v=2 </span><span class="se">\\</span><span class="sh">
  --hostname-override=</span><span class="k">${</span><span class="nv">HOSTNAME</span><span class="k">}</span><span class="sh"> </span><span class="se">\\</span><span class="sh">
  --allow-privileged=true
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
</span><span class="no">EOF
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  --hostname-override=${HOSTNAME} \\
  --allow-privileged=true
</code></pre></div></div>

<p>These flags are different from Kubernetes the Hard Way, because in our cloud server setup, the kubelets won’t pick up the correct hostname, so this would cause some problems.
For things to work on this set-up we need those lines.
The <code class="highlighter-rouge">--alow-privileged=true</code>, we need that, because the network run in pod so we need to allow it.</p>

<h2 id="configuring-kubeproxy">Configuring kubeproxy</h2>

<p>Let’s set up our systemd service for kubeproxy and then start-up all of our 3 services.</p>

<p>Execute the following commands on both of the worker nodes:</p>

<p>Move the files into place:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo mv </span>kube-proxy.kubeconfig /var/lib/kube-proxy/kubeconfig
</code></pre></div></div>

<p>Then, create the kube-proxy config file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | sudo tee /var/lib/kube-proxy/kube-proxy-config.yaml
kind: KubeProxyConfiguration
apiVersion: kubeproxy.config.k8s.io/v1alpha1
clientConnection:
  kubeconfig: "/var/lib/kube-proxy/kubeconfig"
mode: "iptables"
clusterCIDR: "10.200.0.0/16"
</span><span class="no">EOF
</span></code></pre></div></div>

<p>Lastly, create the kube-proxy unit file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | sudo tee /etc/systemd/system/kube-proxy.service
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-proxy </span><span class="se">\\</span><span class="sh">
  --config=/var/lib/kube-proxy/kube-proxy-config.yaml
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
</span><span class="no">EOF
</span></code></pre></div></div>

<p>The flag <code class="highlighter-rouge">--config=/var/lib/kube-proxy/kube-proxy-config.yaml</code> points at the kube-proxy configuration file.</p>

<p>Now that all of our services are configured, we can start them up</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Reload systemd unit files (needed to run everytime we update unit files)</span>
<span class="nb">sudo </span>systemctl daemon-reload

<span class="nb">sudo </span>systemctl <span class="nb">enable </span>containerd kubelet kube-proxy

<span class="nb">sudo </span>systemctl start containerd kubelet kube-proxy
</code></pre></div></div>

<p>Then, we can check the status of the services:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl status containerd kubelet kube-proxy
</code></pre></div></div>

<p>They should be all active and running.</p>

<p>Then, verify from any controller node by running</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get nodes
</code></pre></div></div>

<p>This should  return the hostnames for both of the worker nodes. They should be in the NotReady status at this point.</p>
:ET