I"Û<h2 id="setting-up-kubernetes-remote-access-and-kubectl">Setting up Kubernetes Remote Access and kubectl</h2>

<p>Weâ€™ve already used kubectl to generate the kubeconfigs and some verification steps.</p>

<p>Kubectl is the kubernetes command line tool, it allows us to interact with Kubernetes clusters from the command line.</p>

<p>We will set up kubectl to allow remote access from our machine in order to manage the cluster remotely.</p>

<p>To do this, we will generate a local kubeconfig that will authenticate as the admin user and access the Kubernetes API through the load balancer.</p>

<h4 id="resources">Resources</h4>

<ul>
  <li><a href="https://kubernetes.io/docs/reference/kubectl/overview/">Kubectl</a></li>
</ul>

<h2 id="configuring-kubectl-for-remote-access">Configuring kubectl for remote access</h2>

<p>Open a ssh tunnel to port 6443 on the kubernetes API load balancer.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">LOAD_BALANCER_IP</span><span class="o">=</span>172.31.108.99
<span class="nv">CLOUD_USER</span><span class="o">=</span>cloud_user

ssh <span class="nt">-L</span> 6443:localhost:6443 <span class="k">${</span><span class="nv">CLOUD_USER</span><span class="k">}</span>@<span class="k">${</span><span class="nv">LOAD_BALANCER_IP</span><span class="k">}</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/kthw

<span class="c"># set up a new kubernetes cluster in the local configuration for kubectl</span>
kubectl config set-cluster kubernetes-the-hard-way <span class="se">\</span>
  <span class="nt">--certificate-authority</span><span class="o">=</span>ca.pem <span class="se">\</span>
  <span class="nt">--embed-certs</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--server</span><span class="o">=</span>https://localhost:6443

<span class="c"># this is going to work because of the ssh tunnel, the traffic will be forwarded through the ssh tunnel to the load balancer</span>
kubectl config set-credentials admin <span class="se">\</span>
  <span class="nt">--client-certificate</span><span class="o">=</span>admin.pem <span class="se">\</span>
  <span class="nt">--client-key</span><span class="o">=</span>admin-key.pem

<span class="c"># a context is just a set of data we use to connect to a server</span>
kubectl config set-context kubernetes-the-hard-way <span class="se">\</span>
  <span class="nt">--cluster</span><span class="o">=</span>kubernetes-the-hard-way <span class="se">\</span>
  <span class="nt">--user</span><span class="o">=</span>admin

kubectl config use-context kubernetes-the-hard-way
</code></pre></div></div>

<p>Then, we can verify that everything is working:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># for now, there are no pods, but it should return no resources found</span>
kubectl get pods

<span class="c"># should return the two worker nodes</span>
kubectl get nodes

<span class="c"># will return client and server version</span>
kubectl version
</code></pre></div></div>

<h2 id="networking">Networking</h2>

<p>Kubernetes provides a powerful networking model which allows pods to communicate with one another over a virtual network.</p>

<h3 id="what-problems-does-the-networking-model-solve">What problems does the networking model solve?</h3>

<ul>
  <li>
    <p>How will containers communicate with each other?</p>
  </li>
  <li>
    <p>What if the containers are on different hosts (worker nodes)?</p>
  </li>
  <li>
    <p>How will containers communicate with services?</p>
  </li>
  <li>
    <p>How will containers be assigned unique IP addresses?</p>
  </li>
</ul>

<h3 id="the-docker-model">The Docker Model</h3>

<p>Kubernetes Model is a response to the Docker Model</p>

<p>Docker allows containers to communicate with one another using a virtual network bridge configured on the host.</p>

<p>Each host has its own virtual network serving all the containers on that host. But we run on problems when we have containers on different hosts, then we have to proxy the traffic from the host to the containers, also making sure that no two containers use the same port on a host.</p>

<p>The Kubernetes networking model was created to overcome those limitations.</p>

<h3 id="the-kubernetes-networking-model">The Kubernetes Networking Model</h3>

<ul>
  <li>
    <p>One virtual network for the whole cluster</p>
  </li>
  <li>
    <p>Each pod has a unique IP within the cluster</p>
  </li>
  <li>
    <p>Each service has a unique IP that is in a different range than pod IPs.</p>
  </li>
</ul>

<h4 id="resources-1">Resources</h4>

<ul>
  <li><a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/">Networking</a></li>
</ul>

<h2 id="cluster-network-architecture">Cluster Network Architecture</h2>

<p>CIDR is a way of allocating IP addresses, and it has a way to specifying a CIDR range.</p>

<ul>
  <li>
    <p>Cluster CIDR: value that we will pass to kubernetes and it tells kubernetes what ip range to use when setting up the network (weâ€™ve used it already when setting up some services: example: systemd unit file for the kube-controller-manager, you can see the flag, cluster cidr)</p>
  </li>
  <li>
    <p>Service Cluster IP Range: ip range for services in the cluster, should <strong>not</strong> overlap with the cluster CIDR range.</p>
  </li>
  <li>
    <p>Pod CIDR: we donâ€™t specify a pod CIDR manually in this guide. the pod CIDR is an ip range for pods on a <strong>specific worker node</strong>, need to fall within the cluster CIDR, but canâ€™t overlap with the pod CIDR for any other nodes. So we are allocating to each node a range of IPs.</p>
    <ul>
      <li>Our networking solution automatically handles this.</li>
    </ul>
  </li>
</ul>

<h4 id="resources-2">Resources</h4>

<ul>
  <li><a href="https://github.com/weaveworks/weave">Weave</a></li>
</ul>
:ET